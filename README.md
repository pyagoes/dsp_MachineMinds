{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd99321",
   "metadata": {},
   "source": [
    "# Telco Churn Prediction Application\n",
    "\n",
    "This project is aimed at predicting customer churn for a telco company using machine learning techniques. The project implements an ML-powered application consisting of various components and technologies.\n",
    "\n",
    "## Project Components\n",
    "\n",
    "1. **User Interface (UI):** The user interface allows users to make on-demand predictions by either typing the feature values or uploading a CSV file. Users can also view past predictions through the interface. The UI is implemented using Streamlit, a Python library for building interactive web applications.\n",
    "\n",
    "2. **API (Application Programming Interface):** The ML model is exposed through an API built with FastAPI, a modern, fast (high-performance) web framework for building APIs with Python. The API has two endpoints: one for making predictions and another for saving the predictions to a database. The ML model is loaded using joblib, a library for serializing Python objects.\n",
    "\n",
    "3. **Database:** Predictions and associated data, such as the used feature values, are stored in a PostgreSQL database. PostgreSQL is a powerful, open-source relational database management system.\n",
    "\n",
    "4. **Prediction Job:** Scheduled predictions are made every 5 minutes using an Apache Airflow DAG (Directed Acyclic Graph). The DAG reads data files from a high-quality data folder, calls the API to make predictions, and saves the predictions to the database.\n",
    "\n",
    "5. **Ingestion Job:** Data quality and validation are performed using Great Expectations, a library that checks for missing values, data types, and other criteria. An Airflow DAG executes the data validation process every 5 minutes to ensure the integrity of the ingested data.\n",
    "\n",
    "6. **Monitoring Dashboard:** A Grafana-based monitoring dashboard is provided to monitor the quality of ingested data and track the drift between training and serving data. Grafana is an open-source analytics and monitoring solution that allows for the creation of customizable dashboards.\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "To set up and run the Telco Churn Prediction Application, follow these steps:\n",
    "\n",
    "1. Clone the project repository from [GitHub link](https://github.com/your-username/repo-name).\n",
    "\n",
    "2. Install the required dependencies by running the following command:\n",
    "\n",
    "   ```\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "3. Set up the PostgreSQL database and configure the database connection parameters in the project settings.\n",
    "\n",
    "4. Configure the API endpoints in the application settings, ensuring they are accessible from the UI and prediction job.\n",
    "\n",
    "5. Set up Apache Airflow and create the necessary DAGs for the prediction job and data validation job.\n",
    "\n",
    "6. Configure the Great Expectations environment and define the data validation criteria.\n",
    "\n",
    "7. Install Grafana and set up the monitoring dashboard, connecting it to the necessary data sources.\n",
    "\n",
    "8. Start the application by running the following command:\n",
    "\n",
    "   ```\n",
    "   python app.py\n",
    "   ```\n",
    "\n",
    "   This will launch the Streamlit UI, allowing users to interact with the Telco Churn Prediction Application.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Access the Streamlit UI by opening a web browser and navigating to the appropriate URL.\n",
    "\n",
    "2. Use the UI to input feature values manually or upload a CSV file containing the feature data.\n",
    "\n",
    "3. Click the \"Predict\" button to make a churn prediction based on the provided input.\n",
    "\n",
    "4. View past predictions by selecting the appropriate option in the UI.\n",
    "\n",
    "5. Monitor the data quality and validation results through the Grafana monitoring dashboard.\n",
    "\n",
    "## Contributing\n",
    "\n",
    "Contributions to the Telco Churn Prediction Application are welcome. If you would like to contribute, please follow these guidelines:\n",
    "\n",
    "1. Fork the repository and create a new branch for your contribution.\n",
    "\n",
    "2. Make your changes and ensure they adhere to the project's coding style and conventions.\n",
    "\n",
    "3. Write appropriate tests to validate your changes.\n",
    "\n",
    "4. Submit a pull request detailing the changes you made and their purpose.\n",
    "\n",
    "5. Your\n",
    "\n",
    " pull request will be reviewed, and once approved, it will be merged into the main repository.\n",
    "\n",
    "Please ensure that you provide a detailed description of your changes when submitting a pull request.\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the [MIT License](LICENSE). You are free to modify and distribute the code as per the terms and conditions of this license.\n",
    "\n",
    "## Contact\n",
    "\n",
    "For any questions or inquiries, please contact:\n",
    "\n",
    "- [Your Name](mailto:your-email@example.com)\n",
    "- [Project Repository](https://github.com/your-username/repo-name)\n",
    "\n",
    "Feel free to reach out with any feedback, suggestions, or issues you may encounter while using the Telco Churn Prediction Application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c103b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
